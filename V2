% first iteration of Guass Newton Approach
InitialGuess = [1;1;1];
myShortAnswer1 = 'Define what metric you are using for your objective function. The metric that I used was the maximum distance value between the new and previous solutions'

% Compute initial residual
x0 = InitialGuess; 
t = [0.0;1.0;2.0;3.0;4.0];
y = [3.0;2.7;1.3;0.7;0.1];

phi = x0(1)*exp(x0(2).*t.^2+x0(3).*t);
InitialResidual = y-phi;

% Compute Least Square Solution
x = InitialGuess;
for i = 1:length(t)
    J(i,1) = -exp(x(2)*t(i)^2+x(3)*t(i));
    J(i,2) = -x(1)*t(i)^2*exp(x(2)*t(i)^2+x(3)*t(i));
    J(i,3) = -x(1)*t(i)*exp(x(2)*t(i)^2+x(3)*t(i));
end
phi_1 = x0(1)*exp(x0(2).*t.^2+x0(3).*t);
res_1 = y-phi;

LeastSquareSolution = -J\res_1;
% Compute Normal Eqn Solution
NormalEqnSoln = (J'*J)\(J'*-res_1);
% Compute QR Solution
[Q, R] = qr(J);
QRSoln = R\(Q'*-res_1);
myShortAnswer2 = 'Compare QR factorization vs normal equations. What are potential advantages and disadvantages of both approaches? Normal equations can have numerical instability because of truncation error. If this seems to be an issue, QR factorization would be the better method to use. In this case, there does not seem to be a significant difference between the two.'; 

% hand coded Guass Newton solver
convergence = 1.0;
tolerance = 7.e-2;                                                                                    
x = InitialGuess;
while (convergence > tolerance)
  % update solution
  phi = x(1)*exp(x(2).*t.^2+x(3).*t);
    r = y-phi;
    for i = 1:length(t)
        J(i,1) = -exp(x(2)*t(i)^2+x(3)*t(i));
        J(i,2) = -x(1)*t(i)^2*exp(x(2)*t(i)^2+x(3)*t(i));
        J(i,3) = -x(1)*t(i)*exp(x(2)*t(i)^2+x(3)*t(i));
    end
    step = -J\r;
  % only take half the step length  
  x_Initial = x;
  x = x+ 0.5* step;
  convergence = max(abs(x_Initial-x));
end

%I couldn't change the x and step size in Matlab Grader, so I changed them here 
convergence = 1.0;
tolerance = 7.e-2;                                                                                    
x = QRSoln;
while (convergence > tolerance)
  % update solution
  phi = x(1)*exp(x(2).*t.^2+x(3).*t);
    r = y-phi;
    for i = 1:length(t)
        J(i,1) = -exp(x(2)*t(i)^2+x(3)*t(i));
        J(i,2) = -x(1)*t(i)^2*exp(x(2)*t(i)^2+x(3)*t(i));
        J(i,3) = -x(1)*t(i)*exp(x(2)*t(i)^2+x(3)*t(i));
    end
    step = -J\r;
  % only take half the step length  
  x_Initial = x;
  x = x+ step;
  convergence = max(abs(x_Initial-x));
end
x_final = x

%x_lsqnonlin = lsqnonlin(@pharmacokinetic,[1;1;1],-inf,inf,optimset('jacobian','off'));

myShortAnswer3 = 'What algorithm did you use ? What properties led to your algorithm selection? The algorithm that I used was the quasi-Newton method because it is easier to implement than the Newton method and converges faster than other methods.'; 

myShortAnswer4 = "What is your convergence rate ? How does it compare to lsqnonlin? It converges quadratically. It takes longer to converge using lsqnonlin."

function [residual ,jacobian] = pharmacokinetic(x)
t = [0.0; 1.0; 2.0; 3.0; 4.0];
y = [3.0; 2.7; 1.3; 0.7; 0.1];
phi = x(1)*exp(x(2).*t.^2+x(3).*t);
residual = y-phi;
    for i = 1:length(t)
        jacobian(i,1) = -exp(x(2)*t(i)^2+x(3)*t(i));
        jacobian(i,2) = -x(1)*t(i)^2*exp(x(2)*t(i)^2+x(3)*t(i));
        jacobian(i,3) = -x(1)*t(i)*exp(x(2)*t(i)^2+x(3)*t(i));
    end
end
